{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/result2/output_song_with_structure.json\n/kaggle/input/result2/output_song_gptno.json\n/kaggle/input/result2/output_song_n_gram.json\n/kaggle/input/result/output_song_baseline.json\n/kaggle/input/result/test_dataset.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **BLEU**","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nimport json","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/result2/output_song_with_structure.json','r') as f:\n    model_with_structure = json.load(f)\nwith open('/kaggle/input/result2/output_song_gptno.json','r') as f:\n    model_no_str = json.load(f)\nwith open('/kaggle/input/result2/output_song_n_gram.json','r') as f:\n    model_ng = json.load(f)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def nltkTokenizer(sentence):\n    tokens = word_tokenize(sentence)\n    return tokens","metadata":{"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"pip install --user fast-bleu","metadata":{"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Collecting fast-bleu\n  Downloading fast-bleu-0.0.89.tar.gz (14 kB)\nBuilding wheels for collected packages: fast-bleu\n  Building wheel for fast-bleu (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fast-bleu: filename=fast_bleu-0.0.89-cp37-cp37m-linux_x86_64.whl size=641534 sha256=7fe2e0db66818132d9a79a6798cb9f213fc184a70522f66b266787c50a41ac5f\n  Stored in directory: /root/.cache/pip/wheels/59/f6/b7/3b841c3f010bc5993afbc1b7d8ed78fedca89747dd735488ae\nSuccessfully built fast-bleu\nInstalling collected packages: fast-bleu\nSuccessfully installed fast-bleu-0.0.89\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"nltkTokenizer(sentence)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nwith_str = []\nfor i in  model_with_structure['output_song_with_structure'][:-1]:\n    with_str.append(nltkTokenizer(re.sub('<.{3,5}>|intro, verse, chorus','',i)))\nno_str = []\nfor i in  model_with_structure['output_song_with_structure'][:-1]:\n    no_str.append(nltkTokenizer(re.sub('\\[\\]','',i)))\nng = []\nfor i in  model_ng['output_song_n_gram']:\n    ng.append(nltkTokenizer(re.sub('  |. .',' ',i)))\n    ","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"with open('../input/result/test_dataset.txt','r') as f:\n    test_data = f.read()","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test = []\nfor i in test_data.split('<Newsong>'):\n    test.append(nltkTokenizer(re.sub('<.{3,5}>|<Newline>|intro,| verse,| chorus','',i)))","metadata":{"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(with_str),len(no_str),len(ng),len(test)","metadata":{"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(358, 358, 358, 358)"},"metadata":{}}]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i =0 \n\nlist_bleu(test[0],[no_str,ng, with_str])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"score = 0\nfor i in range(0,358):\n    references =  [test[i]]\n    candidates =  [with_str[i]]\n    score += corpus_bleu(references, candidates)\nprint('with structure', score/358) ","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 3-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"with structure 0.27850996927578353\n","output_type":"stream"}]},{"cell_type":"code","source":"score = 0\nfor i in range(0,358):\n    references =  [test[i]]\n    candidates =  [no_str[i]]\n    score += corpus_bleu(references, candidates)\nprint('with structure', score/358) ","metadata":{"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"with structure 0.3094454666305401\n","output_type":"stream"}]},{"cell_type":"code","source":"score = 0\nfor i in range(0,358):\n    references =  [test[i]]\n    candidates =  [ng[i]]\n    score += corpus_bleu(references, candidates)\nprint('with structure', score/358) ","metadata":{"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 4-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"with structure 0.19783657535750013\n","output_type":"stream"}]},{"cell_type":"code","source":"#this is BLEU-4","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# **Jaccard**","metadata":{}},{"cell_type":"markdown","source":"Jointly Measuring Diversity and Quality in Text Generation Models\n https://github.com/IAmS4n/TextGenerationEvaluationMetrics/tree/789aa6141784293984ead53aea3eb579952d3f46","metadata":{}},{"cell_type":"code","source":"from nltk.translate.bleu_score import ngrams\nfrom collections import Counter\nfrom functools import reduce\n\nimport numpy as np\n\nclass metric_names:\n    jaccard = \"Jaccard\"\n    sorensen = \"Sorensen\"\n    canberra = \"Canberra\"\n    minkowski = \"Minkowski\"\n    BLEU = \"BLEU\"\n    SelfBLEU = \"SelfBLEU\"\n\n\ndef get_ngrams(sentences, n):\n    f = lambda x: (list(ngrams(x, n)) if len(x) >= n else [])\n    return list(map(f, sentences))\n\n\nclass MultisetDistances:\n\n    def __init__(self, references, min_n=3, max_n=5):\n        super().__init__()\n        # print('multiset distances init upto {}!'.format(max_n))\n        self.references = references\n        self.max_n = max_n\n        self.min_n = min_n\n        assert self.max_n >= self.min_n\n        assert self.min_n >= 1\n        self.ref_ngrams = self._get_ngrams(references)\n\n    def get_cached_fields(self):\n        return self.ref_ngrams,\n\n    def _get_ngrams(self, sentences):\n        samples_size = len(sentences)\n        all_counters = [Counter([x for y in get_ngrams(sentences, n + 1) for x in y])\n                        for n in range(self.max_n)]\n        for n_counter in all_counters:\n            for k in n_counter.keys():\n                n_counter[k] /= samples_size\n        return all_counters\n\n    def get_ngram_stuff(self, sentences):\n        sample_ngrams = self._get_ngrams(sentences)\n        ngrams_intersection = [sample_ngrams[i] & self.ref_ngrams[i]\n                               for i in range(self.max_n)]  # intersection:  min(c[x], d[x])\n        ngrams_union = [sample_ngrams[i] | self.ref_ngrams[i]\n                        for i in range(self.max_n)]  # union:  max(c[x], d[x])\n        ngrams_abs_diff = [ngrams_union[i] - ngrams_intersection[i] \\\n                           for i in range(self.max_n)]\n        ngrams_added = [sample_ngrams[i] + self.ref_ngrams[i]\n                        for i in range(self.max_n)]\n\n        return ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added\n\n    def _final_average(self, score_value):\n        return np.power(reduce(lambda x, y: x * y, score_value), 1. / float(len(score_value)))\n\n    def _jaccard(self, ngrams_intersection, ngrams_union):\n        jaccard_value = [float(sum(ngrams_intersection[n].values())) / sum(ngrams_union[n].values()) for n in\n                         range(self.max_n)]\n        return jaccard_value\n\n    def get_jaccard_score(self, sentences):\n        #print('Jaccard distances preprocess upto {}!'.format(self.max_n))\n        ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added = self.get_ngram_stuff(sentences)\n\n        jaccard_value = self._jaccard(ngrams_intersection=ngrams_intersection, ngrams_union=ngrams_union)\n\n        return {n: self._final_average(jaccard_value[:n]) for n in range(self.min_n, self.max_n + 1)}\n\n    def _sorensen(self, ngrams_abs_diff, ngrams_added):\n        sorensen_value = [float(sum(ngrams_abs_diff[n].values())) / sum(ngrams_added[n].values()) for n in\n                          range(self.max_n)]\n        return sorensen_value\n\n    def get_sorensen_score(self, sentences):\n        print('Sorensen distances preprocess upto {}!'.format(self.max_n))\n        ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added = self.get_ngram_stuff(sentences)\n\n        sorensen_value = self._sorensen(ngrams_abs_diff=ngrams_abs_diff, ngrams_added=ngrams_added)\n\n        return {n: self._final_average(sorensen_value[:n]) for n in range(self.min_n, self.max_n + 1)}\n\n    def _canberra(self, ngrams_abs_diff, ngrams_added):\n        canberra_value = [np.sum([ngrams_abs_diff[n][key] / float(ngrams_added[n][key]) for key in ngrams_abs_diff[n]])\n                          for n in range(self.max_n)]\n        return canberra_value\n\n    def get_canberra_score(self, sentences):\n        print('Canberra distances preprocess upto {}!'.format(self.max_n))\n        ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added = self.get_ngram_stuff(sentences)\n        canberra_value = self._canberra(ngrams_abs_diff=ngrams_abs_diff, ngrams_added=ngrams_added)\n        return {n: self._final_average(canberra_value[:n]) for n in range(self.min_n, self.max_n + 1)}\n\n    def _minkowski(self, ngrams_abs_diff, p):\n        minkowski_value = [np.power(np.sum(np.power(list(ngrams_abs_diff[n].values()), p)), 1. / p) for n in\n                           range(self.max_n)]\n        return minkowski_value\n\n    def get_minkowski_score(self, sentences, p):\n        print('Minkowski (p={}) distances preprocess upto {}!'.format(p, self.max_n))\n        ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added = self.get_ngram_stuff(sentences)\n\n        minkowski_value = self._minkowski(ngrams_abs_diff=ngrams_abs_diff, p=p)\n\n        return {n: self._final_average(minkowski_value[:n]) for n in range(self.min_n, self.max_n + 1)}\n\n    def get_all_score(self, sentences, max_mikowski_order=3):\n        print('multiset distances preprocess upto {}!'.format(self.max_n))\n        ngrams_intersection, ngrams_union, ngrams_abs_diff, ngrams_added = self.get_ngram_stuff(sentences)\n\n        temp_results = {}\n\n        print('multiset distances evaluating upto {}!'.format(self.max_n))\n        temp_results[metric_names.jaccard] = self._jaccard(ngrams_intersection=ngrams_intersection,\n                                                           ngrams_union=ngrams_union)\n        temp_results[metric_names.sorensen] = self._sorensen(ngrams_abs_diff=ngrams_abs_diff, ngrams_added=ngrams_added)\n        temp_results[metric_names.canberra] = self._canberra(ngrams_abs_diff=ngrams_abs_diff, ngrams_added=ngrams_added)\n        for p in range(1, max_mikowski_order + 1):\n            temp_results['p%d-%s' % (p, metric_names.minkowski)] = self._minkowski(ngrams_abs_diff=ngrams_abs_diff, p=p)\n\n        result = {}\n        for key in temp_results:\n            for n in range(self.min_n, self.max_n + 1):\n                result[key + '%d' % n] = self._final_average(temp_results[key][:n])\n        return result","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"msj_distance","metadata":{"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{3: 0.0, 4: 0.0, 5: 0.0}"},"metadata":{}}]},{"cell_type":"code","source":"score = 0\n\nfor i in range(0,358,5):\n    references =  test[i:i+5]\n    candidates =  with_str[i:i+5]\n\n    msd = MultisetDistances(references=references)\n    msj_distance = msd.get_jaccard_score(sentences=candidates)\n    score += msj_distance[3]\n    #fbd = FBD(references=references, model_name=\"bert-base-uncased\", bert_model_dir=\"/tmp/Bert/\")\n\nprint('with structure')\nprint('msj_distance',score/len(range(0,358,5)))\nscore = 0\nfor i in range(0,358,5):\n    references =  test[i:i+5]\n    candidates =  no_str[i:i+5]\n\n    msd = MultisetDistances(references=references)\n    msj_distance = msd.get_jaccard_score(sentences=candidates)\n    score += msj_distance[3]\nprint('no structure','msj_distance',score/len(range(0,358,5)))\nscore = 0\nfor i in range(0,358,5):\n    references =  test[i:i+5]\n    candidates =  ng[i:i+5]\n\n    msd = MultisetDistances(references=references)\n    msj_distance = msd.get_jaccard_score(sentences=candidates)\n    score += msj_distance[3]\nprint('n-gram','msj_distance',score/len(range(0,358,5)))","metadata":{"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"with structure\nmsj_distance 0.014830080896122248\nno structure msj_distance 0.01470584000742136\nn-gram msj_distance 0.0\n","output_type":"stream"}]},{"cell_type":"code","source":" ","metadata":{},"execution_count":null,"outputs":[]}]}